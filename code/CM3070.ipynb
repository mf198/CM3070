{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4b18613",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Credit Card Fraud Detection System  \n",
    "  \n",
    "## Project Prototype\n",
    "  \n",
    "  \n",
    "Author: Marco Fontana"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6618ea38-80f4-4bf2-8b7d-bea0c7ef9756",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## **Implementation** \n",
    "\n",
    "Before starting code development, I prepared an environment that would allow me to write and test the code and track all the changes I made.   \n",
    "The project is written in a Jupyter Notebook, in Python, and uses several third-party libraries specific to Machine Learning and Deep Learning algorithms.  \n",
    "Therefore, before I could write code, I had to install all the necessary components on my PC's operating system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28038ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (2.0.2)\n",
      "Requirement already satisfied: pandas in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: tensorflow in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (2.18.0)\n",
      "Requirement already satisfied: scikit-learn in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (1.6.1)\n",
      "Requirement already satisfied: imbalanced-learn in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (0.13.0)\n",
      "Requirement already satisfied: matplotlib in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (3.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from tensorflow) (25.1.24)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from tensorflow) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from tensorflow) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from tensorflow) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from tensorflow) (3.8.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from scikit-learn) (1.15.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from imbalanced-learn) (0.1.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from matplotlib) (4.55.6)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/kino/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "!pip install numpy pandas tensorflow scikit-learn imbalanced-learn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "913404df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE, RandomOverSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd501fdb-95f3-4795-94c7-bdc37a1648e6",
   "metadata": {},
   "source": [
    "### **Dataset analysis**\n",
    "\n",
    "The first phase of the project is dedicated to the analysis of the dataset. Before proceeding to the implementation of the code, it is necessary to have a deep understanding of the available data in order to understand whether modifications are necessary to make the dataset suitable for ML and DL algorithms, thus increasing their performance.\n",
    "Furthermore, since this dataset contains financial data, it is necessary to verify that there is no sensitive information of the user or payment institution, which could lead to confidentiality or ethical problems.\n",
    "\n",
    "In the description of the dataset[] it is stated that for confidentiality reasons the content has been obscured via a PCA[] transformation; the feature name itself has been changed to a symbolic name (V1 to V28); the only features that have not been transformed or obfuscated are Time and Amount.  \n",
    "The feature Time represents the number of seconds between each transaction and the first transaction, while Amount represents the amount of the transaction.  \n",
    "\n",
    "Transforming and obfuscating the data and features of the dataset ensures that it does not contain sensitive information and guarantees that there are no confidentiality issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "368b6d72-36f9-4c4f-9316-f8ae64a3cbe5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'creditcard.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load the dataset\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcreditcard.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Show dataset info\u001b[39;00m\n\u001b[1;32m      5\u001b[0m df\u001b[38;5;241m.\u001b[39minfo()\n",
      "File \u001b[0;32m~/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniforge3/envs/rapids-24.12/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'creditcard.csv'"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('creditcard.csv')\n",
    "\n",
    "# Show dataset info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359aa9f9-ea78-4af3-b8c2-bd8ebc20654d",
   "metadata": {},
   "source": [
    "The dataset consists of 284807 records and is described by 31 features.  \n",
    "The data are all of type float64, except for the feature 'Class' which is of type int64.\n",
    "\n",
    "#### **Checking for missing values**\n",
    "\n",
    "The next step is to check for missing values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413cef4d-480b-41ed-adaa-0da8876553e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nNumber of missing values:\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a944d9fd-f5d8-4ae6-8442-ccad3bd3588b",
   "metadata": {},
   "source": [
    "The dataset contains no missing values, so no manual editing operation is required.  \n",
    "  \n",
    "By visualizing an example of the records in the dataset, I can understand whether other operations are needed on the data that can improve performance with the ML and DL algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437474b6-81f6-47bc-9af9-fc81cd5d602f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display the first 5 records of the dataset\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d821da-77a7-46fa-921a-a40922cf9f1c",
   "metadata": {},
   "source": [
    "From the analysis of some records, it can be seen that the Time and Amount features have not been transformed.\n",
    "The Time feature is not useful in my research, since it does not provide a particular pattern related to the transaction; I could transform it into a date and time value, but since I have no information about the time of the first transaction I would have to create non-real data; that is why I decided to remove it from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bdf6c22-24ff-4372-95da-40b23e61c12b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df = df.drop(columns=['Time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da17c9f7-9bce-4470-9be1-723278911fe6",
   "metadata": {},
   "source": [
    "The 'Amount' feature is of type int64 and the values it contains can vary widely between transactons.  \n",
    "Some ML algorithms (SVM, gradient boosting, etc.) perform better when features are on a similar scale, and since the feature ‘Amount’ can have a significant variance, scaling helps stabilise the performance of the model.\n",
    "\n",
    "I did not delete the 'Amount' feature because the economic value of the transaction can be of great importance for identifying fraud patterns.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a8d207f-e9a7-4992-a33b-bbc6c45cfca0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Apply scaling to the 'Amount' feature\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAmount\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m StandardScaler()\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mdf\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAmount\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "#Apply scaling to the 'Amount' feature\n",
    "df['Amount'] = StandardScaler().fit_transform(df[['Amount']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e03e248-3e7d-40b1-8002-8c5752d80fb8",
   "metadata": {},
   "source": [
    "The StandardScaler is a data preprocessing technique commonly used in machine learning to scale or normalize features so that they have a mean of 0 and a standard deviation of 1. This is particularly important for many machine learning algorithms that are sensitive to the scale of input features, such as SVMs (Support Vector Machines), k-NN (k-Nearest Neighbors), and Logistic Regression. \n",
    "  \n",
    "The state of the dataset after changes are made can be seen in the output below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8758f203-c92c-41b8-b3bf-be5f1a5ce0e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6117f8",
   "metadata": {},
   "source": [
    "The dataset description page contains information on the distrubution of its two classes two classes 'non-fraud' (0) and 'fraud' (1).  \n",
    "The amount of records of the two types is very different, as can be seen in the following output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b72e82e4-e2b8-4e72-8510-b88db0a5d30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Class 1 records: 0.173%\n"
     ]
    }
   ],
   "source": [
    "# Convert the Class column to a NumPy array\n",
    "class_array = df['Class'].to_numpy()\n",
    "\n",
    "# Calculate the percentage of Class 1 records (frauds)\n",
    "percentage_class_1 = (np.sum(class_array == 1) / len(class_array)) * 100\n",
    "\n",
    "print(f\"Percentage of Class 1 records: {percentage_class_1:.3f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ee8504",
   "metadata": {},
   "source": [
    "The large imbalance in the distribution of classes in the dataset is a problem for some ML and DL algorithms, and so it is necessary to use techniques for its balancing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1344994f-b1c9-41fb-b07e-ed2418c0ea55",
   "metadata": {},
   "source": [
    "#### Balancing the dataset\n",
    "\n",
    "To obtain a dataset with an equivalent number of records for its classes, I will use several techniques and then compare the results with ML and DL algorithms. The goal is to test which method generates synthetic data that most closely resembles real data; artificially generated fraud records in fact could be classified as false negatives. By comparing the results I will be able to determine which of the balancing techniques is the most appropriate for generating this type of data.\n",
    "\n",
    "It is important to note that the balancing of the dataset is done __after__ its division into training and test data, so that the latter contain no ‘synthetic’ data. \n",
    "\n",
    "I created a class which uses several oversampling methods: SMOTE, ADASYN, Borderline-SMOTE, SVMSMOTE and Random Oversampling. The selection of algorithms was evaluated after reading several researches that used them in their projects deemed them the best for oversampling the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "131c2b68-49ab-4636-b37a-a95dd5bc4d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OversamplingTechniques:\n",
    "    def __init__(self, X, y):\n",
    "        \"\"\"\n",
    "        Initialize the class with the original dataset features (X) and target (y).\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.results = {}\n",
    "\n",
    "    def apply_smote(self):\n",
    "        \"\"\"\n",
    "        Apply SMOTE to the dataset and save the oversampled dataset.\n",
    "        \"\"\"\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_resampled, y_resampled = smote.fit_resample(self.X, self.y)\n",
    "        self.results['SMOTE'] = (X_resampled, y_resampled)\n",
    "\n",
    "    def apply_adasyn(self):\n",
    "        \"\"\"\n",
    "        Apply ADASYN to the dataset and save the oversampled dataset.\n",
    "        \"\"\"\n",
    "        adasyn = ADASYN(random_state=42)\n",
    "        X_resampled, y_resampled = adasyn.fit_resample(self.X, self.y)\n",
    "        self.results['ADASYN'] = (X_resampled, y_resampled)\n",
    "\n",
    "    def apply_borderline_smote(self):\n",
    "        \"\"\"\n",
    "        Apply Borderline-SMOTE to the dataset and save the oversampled dataset.\n",
    "        \"\"\"\n",
    "        borderline_smote = BorderlineSMOTE(random_state=42)\n",
    "        \n",
    "        X_resampled, y_resampled = borderline_smote.fit_resample(self.X, self.y)\n",
    "        self.results['Borderline-SMOTE'] = (X_resampled, y_resampled)\n",
    "\n",
    "    def apply_random_oversampling(self):\n",
    "        \"\"\"\n",
    "        Apply Random Oversampling to the dataset and save the oversampled dataset.\n",
    "        \"\"\"\n",
    "        random_oversampler = RandomOverSampler(random_state=42)\n",
    "        X_resampled, y_resampled = random_oversampler.fit_resample(self.X, self.y)\n",
    "        self.results['Random Oversampling'] = (X_resampled, y_resampled)\n",
    "    \n",
    "    def get_resampled_data(self, method):\n",
    "        \"\"\"\n",
    "        Retrieve the resampled dataset for a given oversampling method.\n",
    "        :param method: String indicating the oversampling method (e.g., 'SMOTE').\n",
    "        :return: Tuple of resampled features (X) and target (y).\n",
    "        \"\"\"\n",
    "        return self.results.get(method, None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddd860e-9108-4966-9db2-d6436a6550f5",
   "metadata": {},
   "source": [
    "Oversampling of the dataset is done on the training data only, so that the test data does not contain synthetic data.\n",
    "I decided to reserve 70% of the dataset for training and the remaining 30% for testing. Before applying oversampling, I separated the labels from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04e1172-c74b-4551-a886-ed49c79f90dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "70b0fc07-d373-4c9f-9669-a359678bf872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "X = df.drop(columns=['Class'])  # Features\n",
    "y = df['Class']                 # Labels\n",
    "\n",
    "# Split the data into train and test sets (to avoid data leakage)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c6c01f-04ff-4f7c-bcc9-0e1e80dd1610",
   "metadata": {},
   "source": [
    "Visualizing the class distribution makes the imbalance of the dataset more evident. \n",
    "There are  284315 class 0 (non-fraud) records and 492 class 1 (fraud) records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "00f6fbcb-b785-4f7b-b004-3879bf56e0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kino/dev/CM3070/code/.final/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'update_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 149\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# Train GAN\u001b[39;00m\n\u001b[1;32m    148\u001b[0m generator_gan, discriminator_gan, gan_model \u001b[38;5;241m=\u001b[39m build_gan(latent_dim, n_features)\n\u001b[0;32m--> 149\u001b[0m \u001b[43mtrain_gan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator_gan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscriminator_gan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgan_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_minority\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;66;03m# Generate synthetic samples\u001b[39;00m\n\u001b[1;32m    152\u001b[0m noise \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X_train_minority), latent_dim))\n",
      "Cell \u001b[0;32mIn[78], line 79\u001b[0m, in \u001b[0;36mtrain_gan\u001b[0;34m(generator, discriminator, gan_model, X_minority, latent_dim, epochs, batch_size)\u001b[0m\n\u001b[1;32m     76\u001b[0m fake_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((batch_size, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Train discriminator\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m d_loss_real \u001b[38;5;241m=\u001b[39m \u001b[43mdiscriminator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m d_loss_fake \u001b[38;5;241m=\u001b[39m discriminator\u001b[38;5;241m.\u001b[39mtrain_on_batch(fake_samples, fake_labels)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# Train generator\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/CM3070/code/.final/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:598\u001b[0m, in \u001b[0;36mTensorFlowTrainer.train_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, return_dict)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdata\u001b[39m():\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m (x, y, sample_weight)\n\u001b[0;32m--> 598\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    599\u001b[0m logs \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mmap_structure(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39marray(x), logs)\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n",
      "File \u001b[0;32m~/dev/CM3070/code/.final/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:224\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps_per_execution), iterator\n\u001b[1;32m    223\u001b[0m     ):\n\u001b[0;32m--> 224\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mone_step_on_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/dev/CM3070/code/.final/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/dev/CM3070/code/.final/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:110\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.one_step_on_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;129m@tf\u001b[39m\u001b[38;5;241m.\u001b[39mautograph\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mdo_not_convert\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mone_step_on_data\u001b[39m(data):\n\u001b[1;32m    109\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Runs a single training step on a batch of data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[1;32m    112\u001b[0m         outputs,\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy,\n\u001b[1;32m    114\u001b[0m         reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    115\u001b[0m     )\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/dev/CM3070/code/.final/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:66\u001b[0m, in \u001b[0;36mTensorFlowTrainer.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     58\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(x)\n\u001b[1;32m     59\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_loss(\n\u001b[1;32m     60\u001b[0m     x\u001b[38;5;241m=\u001b[39mx,\n\u001b[1;32m     61\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     65\u001b[0m )\n\u001b[0;32m---> 66\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_loss_tracker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_state\u001b[49m(\n\u001b[1;32m     67\u001b[0m     loss, sample_weight\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mshape(tree\u001b[38;5;241m.\u001b[39mflatten(x)[\u001b[38;5;241m0\u001b[39m])[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     68\u001b[0m )\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mscale_loss(loss)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'update_state'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "# Step 1: Read the dataset\n",
    "# Replace 'creditcard.csv' with the correct path to the dataset\n",
    "df = pd.read_csv('creditcard.csv')\n",
    "\n",
    "# Step 2: Preprocess the data\n",
    "# Separate features (X) and target (y)\n",
    "X = df.drop(columns=['Class'])\n",
    "y = df['Class']\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Separate majority and minority classes in training data\n",
    "X_train_majority = X_train[y_train == 0]\n",
    "X_train_minority = X_train[y_train == 1]\n",
    "\n",
    "# Step 3: Define GAN architecture\n",
    "def build_gan(latent_dim, n_features):\n",
    "    \"\"\"\n",
    "    Build Generator, Discriminator, and GAN for GAN-based oversampling.\n",
    "    \"\"\"\n",
    "    # Generator\n",
    "    generator = tf.keras.Sequential([\n",
    "        layers.Dense(64, activation='relu', input_dim=latent_dim),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(n_features, activation='tanh')\n",
    "    ])\n",
    "\n",
    "    # Discriminator\n",
    "    discriminator = tf.keras.Sequential([\n",
    "        layers.Dense(128, activation='relu', input_dim=n_features),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    discriminator.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002), loss='binary_crossentropy')\n",
    "\n",
    "    # GAN\n",
    "    discriminator.trainable = False\n",
    "    gan_input = layers.Input(shape=(latent_dim,))\n",
    "    gan_output = discriminator(generator(gan_input))\n",
    "    gan_model = Model(gan_input, gan_output)\n",
    "    gan_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002), loss='binary_crossentropy')\n",
    "\n",
    "    return generator, discriminator, gan_model\n",
    "\n",
    "# Step 4: Train GAN\n",
    "def train_gan(generator, discriminator, gan_model, X_minority, latent_dim, epochs, batch_size):\n",
    "    \"\"\"\n",
    "    Train GAN to generate synthetic samples for the minority class.\n",
    "    \"\"\"\n",
    "    for epoch in range(epochs):\n",
    "        # Generate fake samples\n",
    "        noise = np.random.normal(0, 1, size=(batch_size, latent_dim))\n",
    "        fake_samples = generator.predict(noise)\n",
    "\n",
    "        # Select real samples\n",
    "        idx = np.random.randint(0, X_minority.shape[0], batch_size)\n",
    "        real_samples = X_minority[idx]\n",
    "\n",
    "        # Labels for real and fake samples\n",
    "        real_labels = np.ones((batch_size, 1))\n",
    "        fake_labels = np.zeros((batch_size, 1))\n",
    "\n",
    "        # Train discriminator\n",
    "        d_loss_real = discriminator.train_on_batch(real_samples, real_labels)\n",
    "        d_loss_fake = discriminator.train_on_batch(fake_samples, fake_labels)\n",
    "\n",
    "        # Train generator\n",
    "        noise = np.random.normal(0, 1, size=(batch_size, latent_dim))\n",
    "        g_loss = gan_model.train_on_batch(noise, real_labels)\n",
    "\n",
    "        # Log progress\n",
    "        if epoch % 1000 == 0:\n",
    "            print(f\"Epoch {epoch}: D Loss Real = {d_loss_real}, D Loss Fake = {d_loss_fake}, G Loss = {g_loss}\")\n",
    "\n",
    "# Step 5: Define WGAN architecture\n",
    "def build_wgan(latent_dim, n_features):\n",
    "    \"\"\"\n",
    "    Build Generator and Critic for WGAN-based oversampling.\n",
    "    \"\"\"\n",
    "    # Generator\n",
    "    generator = tf.keras.Sequential([\n",
    "        layers.Dense(64, activation='relu', input_dim=latent_dim),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(n_features, activation='tanh')\n",
    "    ])\n",
    "\n",
    "    # Critic\n",
    "    critic = tf.keras.Sequential([\n",
    "        layers.Dense(128, activation='relu', input_dim=n_features),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(1)  # Outputs a score, not a probability\n",
    "    ])\n",
    "    critic.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002), loss='mse')  # Critic loss\n",
    "\n",
    "    return generator, critic\n",
    "\n",
    "# Step 6: Train WGAN\n",
    "def train_wgan(generator, critic, X_minority, latent_dim, epochs, batch_size, critic_steps=5):\n",
    "    \"\"\"\n",
    "    Train WGAN to generate synthetic samples for the minority class.\n",
    "    \"\"\"\n",
    "    for epoch in range(epochs):\n",
    "        for _ in range(critic_steps):\n",
    "            # Generate fake samples\n",
    "            noise = np.random.normal(0, 1, size=(batch_size, latent_dim))\n",
    "            fake_samples = generator.predict(noise)\n",
    "\n",
    "            # Select real samples\n",
    "            idx = np.random.randint(0, X_minority.shape[0], batch_size)\n",
    "            real_samples = X_minority[idx]\n",
    "\n",
    "            # Train critic\n",
    "            real_labels = np.ones((batch_size, 1))\n",
    "            fake_labels = -np.ones((batch_size, 1))\n",
    "            real_loss = critic.train_on_batch(real_samples, real_labels)\n",
    "            fake_loss = critic.train_on_batch(fake_samples, fake_labels)\n",
    "\n",
    "        # Train generator\n",
    "        noise = np.random.normal(0, 1, size=(batch_size, latent_dim))\n",
    "        g_loss = critic.train_on_batch(generator.predict(noise), real_labels)\n",
    "\n",
    "        # Log progress\n",
    "        if epoch % 1000 == 0:\n",
    "            print(f\"Epoch {epoch}: Critic Loss = {real_loss + fake_loss}, G Loss = {g_loss}\")\n",
    "\n",
    "# Step 7: Apply GAN for oversampling\n",
    "latent_dim = 32\n",
    "n_features = X_train.shape[1]\n",
    "batch_size = 64\n",
    "epochs = 5000\n",
    "\n",
    "# Train GAN\n",
    "generator_gan, discriminator_gan, gan_model = build_gan(latent_dim, n_features)\n",
    "train_gan(generator_gan, discriminator_gan, gan_model, X_train_minority, latent_dim, epochs, batch_size)\n",
    "\n",
    "# Generate synthetic samples\n",
    "noise = np.random.normal(0, 1, size=(len(X_train_minority), latent_dim))\n",
    "synthetic_samples_gan = generator_gan.predict(noise)\n",
    "\n",
    "# Combine synthetic samples with original dataset\n",
    "X_train_gan = np.vstack((X_train, synthetic_samples_gan))\n",
    "y_train_gan = np.hstack((y_train, np.ones(len(synthetic_samples_gan))))\n",
    "\n",
    "# Shuffle the dataset\n",
    "X_train_gan, y_train_gan = shuffle(X_train_gan, y_train_gan, random_state=42)\n",
    "\n",
    "# Step 8: Apply WGAN for oversampling\n",
    "generator_wgan, critic_wgan = build_wgan(latent_dim, n_features)\n",
    "train_wgan(generator_wgan, critic_wgan, X_train_minority, latent_dim, epochs, batch_size)\n",
    "\n",
    "# Generate synthetic samples\n",
    "noise = np.random.normal(0, 1, size=(len(X_train_minority), latent_dim))\n",
    "synthetic_samples_wgan = generator_wgan.predict(noise)\n",
    "\n",
    "# Combine synthetic samples with original dataset\n",
    "X_train_wgan = np.vstack((X_train, synthetic_samples_wgan))\n",
    "y_train_wgan = np.hstack((y_train, np.ones(len(synthetic_samples_wgan))))\n",
    "\n",
    "# Shuffle the dataset\n",
    "X_train_wgan, y_train_wgan = shuffle(X_train_wgan, y_train_wgan, random_state=42)\n",
    "\n",
    "# Step 9: Results\n",
    "print(\"GAN-oversampled dataset shape:\", X_train_gan.shape, y_train_gan.shape)\n",
    "print(\"WGAN-oversampled dataset shape:\", X_train_wgan.shape, y_train_wgan.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cb5a628f-9846-4be8-8899-defb81c47a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution Before oversampling:\n",
      "Class\n",
      "0    284315\n",
      "1       492\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display class distribution before any oversampling technique is applied\n",
    "print(\"Class Distribution Before oversampling:\")\n",
    "print(df['Class'].value_counts())\n",
    "df['Class'].value_counts().plot(kind='bar', title='Class Distribution (Before oversampling)', xlabel='Class', ylabel='Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c0cc178f-ec44-49f2-a786-be689b1e21cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANOversampling:\n",
    "    def __init__(self, X, y):\n",
    "        \"\"\"\n",
    "        Initialize the class with the original dataset features (X) and target (y).\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.results = {}\n",
    "\n",
    "    def apply_gan(self, latent_dim=100, epochs=5000, batch_size=64):\n",
    "        \"\"\"\n",
    "        Apply GAN to generate synthetic data for the minority class.\n",
    "        \"\"\"\n",
    "        X_minority = self.X[self.y == 1]  # Filter minority class\n",
    "        n_minority_samples = X_minority.shape[0]\n",
    "        generator, discriminator, gan_model = self._build_gan(latent_dim, X_minority.shape[1])\n",
    "\n",
    "        # Train GAN\n",
    "        self._train_gan(generator, discriminator, gan_model, X_minority, latent_dim, epochs, batch_size)\n",
    "\n",
    "        # Generate synthetic samples\n",
    "        noise = np.random.normal(0, 1, size=(n_minority_samples, latent_dim))\n",
    "        synthetic_data = generator.predict(noise)\n",
    "\n",
    "        # Combine synthetic and original data\n",
    "        X_resampled = np.vstack((self.X, synthetic_data))\n",
    "        y_resampled = np.hstack((self.y, np.ones(len(synthetic_data))))\n",
    "\n",
    "        # Shuffle the dataset\n",
    "        X_resampled, y_resampled = shuffle(X_resampled, y_resampled, random_state=42)\n",
    "\n",
    "        self.results['GAN'] = (X_resampled, y_resampled)\n",
    "\n",
    "    def apply_wgan(self, latent_dim=100, epochs=5000, batch_size=64):\n",
    "        \"\"\"\n",
    "        Apply WGAN to generate synthetic data for the minority class.\n",
    "        \"\"\"\n",
    "        X_minority = self.X[self.y == 1]  # Filter minority class\n",
    "        n_minority_samples = X_minority.shape[0]\n",
    "        generator, critic = self._build_wgan(latent_dim, X_minority.shape[1])\n",
    "\n",
    "        # Train WGAN\n",
    "        self._train_wgan(generator, critic, X_minority, latent_dim, epochs, batch_size)\n",
    "\n",
    "        # Generate synthetic samples\n",
    "        noise = np.random.normal(0, 1, size=(n_minority_samples, latent_dim))\n",
    "        synthetic_data = generator.predict(noise)\n",
    "\n",
    "        # Combine synthetic and original data\n",
    "        X_resampled = np.vstack((self.X, synthetic_data))\n",
    "        y_resampled = np.hstack((self.y, np.ones(len(synthetic_data))))\n",
    "\n",
    "        # Shuffle the dataset\n",
    "        X_resampled, y_resampled = shuffle(X_resampled, y_resampled, random_state=42)\n",
    "\n",
    "        self.results['WGAN'] = (X_resampled, y_resampled)\n",
    "\n",
    "    # --- Helper functions for GAN ---\n",
    "    def _build_gan(self, latent_dim, n_features):\n",
    "        \"\"\"\n",
    "        Build the generator, discriminator, and GAN model.\n",
    "        \"\"\"\n",
    "        # Generator\n",
    "        generator = tf.keras.Sequential([\n",
    "            layers.Dense(128, activation='relu', input_dim=latent_dim),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(n_features, activation='tanh')\n",
    "        ])\n",
    "\n",
    "        # Discriminator\n",
    "        discriminator = tf.keras.Sequential([\n",
    "            layers.Dense(128, activation='relu', input_dim=n_features),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        discriminator.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # GAN (Generator + Discriminator)\n",
    "        discriminator.trainable = False\n",
    "        gan_input = layers.Input(shape=(latent_dim,))\n",
    "        gan_output = discriminator(generator(gan_input))\n",
    "        gan_model = Model(gan_input, gan_output)\n",
    "        gan_model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "        return generator, discriminator, gan_model\n",
    "\n",
    "    def _train_gan(self, generator, discriminator, gan_model, X_minority, latent_dim, epochs, batch_size):\n",
    "        \"\"\"\n",
    "        Train the GAN model.\n",
    "        \"\"\"\n",
    "        for epoch in range(epochs):\n",
    "            # Generate fake data\n",
    "            noise = np.random.normal(0, 1, size=(batch_size, latent_dim))\n",
    "            fake_data = generator.predict(noise)\n",
    "\n",
    "            # Select real data\n",
    "            idx = np.random.randint(0, X_minority.shape[0], batch_size)\n",
    "            real_data = X_minority.iloc[idx]\n",
    "\n",
    "            # Train discriminator\n",
    "            d_loss_real = discriminator.train_on_batch(real_data, np.ones((batch_size, 1)))\n",
    "            d_loss_fake = discriminator.train_on_batch(fake_data, np.zeros((batch_size, 1)))\n",
    "\n",
    "            # Train generator\n",
    "            noise = np.random.normal(0, 1, size=(batch_size, latent_dim))\n",
    "            g_loss = gan_model.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "\n",
    "            # Optionally log progress\n",
    "            if epoch % 1000 == 0:\n",
    "                print(f\"Epoch {epoch}, D Loss: {d_loss_real + d_loss_fake}, G Loss: {g_loss}\")\n",
    "\n",
    "    # --- Helper functions for WGAN ---\n",
    "    def _build_wgan(self, latent_dim, n_features):\n",
    "        \"\"\"\n",
    "        Build the generator and critic for WGAN.\n",
    "        \"\"\"\n",
    "        # Generator\n",
    "        generator = tf.keras.Sequential([\n",
    "            layers.Dense(128, activation='relu', input_dim=latent_dim),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(n_features, activation='tanh')\n",
    "        ])\n",
    "\n",
    "        # Critic (similar to a discriminator, but outputs real-valued scores instead of probabilities)\n",
    "        critic = tf.keras.Sequential([\n",
    "            layers.Dense(128, activation='relu', input_dim=n_features),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(1)\n",
    "        ])\n",
    "        critic.compile(optimizer='adam', loss='mse')  # Loss function for WGAN critic\n",
    "\n",
    "        return generator, critic\n",
    "\n",
    "    def _train_wgan(self, generator, critic, X_minority, latent_dim, epochs, batch_size):\n",
    "        \"\"\"\n",
    "        Train the WGAN model.\n",
    "        \"\"\"\n",
    "        for epoch in range(epochs):\n",
    "            # Generate fake data\n",
    "            noise = np.random.normal(0, 1, size=(batch_size, latent_dim))\n",
    "            fake_data = generator.predict(noise)\n",
    "\n",
    "            # Select real data\n",
    "            idx = np.random.randint(0, X_minority.shape[0], batch_size)\n",
    "            real_data = X_minority[idx]\n",
    "\n",
    "            # Train critic\n",
    "            real_loss = critic.train_on_batch(real_data, np.ones((batch_size, 1)))\n",
    "            fake_loss = critic.train_on_batch(fake_data, -np.ones((batch_size, 1)))\n",
    "\n",
    "            # Train generator\n",
    "            noise = np.random.normal(0, 1, size=(batch_size, latent_dim))\n",
    "            g_loss = critic.train_on_batch(generator.predict(noise), np.ones((batch_size, 1)))\n",
    "\n",
    "            # Optionally log progress\n",
    "            if epoch % 1000 == 0:\n",
    "                print(f\"Epoch {epoch}, Critic Loss: {real_loss + fake_loss}, G Loss: {g_loss}\")\n",
    "\n",
    "    def get_resampled_data(self, method):\n",
    "        \"\"\"\n",
    "        Retrieve the resampled dataset for a given oversampling method.\n",
    "        :param method: String indicating the oversampling method (e.g., 'SMOTE', 'GAN', or 'WGAN').\n",
    "        :return: Tuple of resampled features (X) and target (y).\n",
    "        \"\"\"\n",
    "        return self.results.get(method, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "269f5852-8387-45ed-8b96-2c4c1298438d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
      "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
      "       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount'],\n",
      "      dtype='object')\n",
      "RangeIndex(start=0, stop=284807, step=1)\n",
      "(284807, 29)\n"
     ]
    }
   ],
   "source": [
    "print(X.columns)  # Check column names\n",
    "print(X.index)    # Check row indices\n",
    "print(X.shape)    # Check shape of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6183b8e3-6bac-4bec-87f4-3fe9d7ee3ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kino/dev/CM3070/code/.final/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'update_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m ganOversampling \u001b[38;5;241m=\u001b[39m GANOversampling(X_train, y_train)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mganOversampling\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gan\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[75], line 19\u001b[0m, in \u001b[0;36mGANOversampling.apply_gan\u001b[0;34m(self, latent_dim, epochs, batch_size)\u001b[0m\n\u001b[1;32m     16\u001b[0m generator, discriminator, gan_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_gan(latent_dim, X_minority\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Train GAN\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_gan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscriminator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgan_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_minority\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Generate synthetic samples\u001b[39;00m\n\u001b[1;32m     22\u001b[0m noise \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, size\u001b[38;5;241m=\u001b[39m(n_minority_samples, latent_dim))\n",
      "Cell \u001b[0;32mIn[75], line 101\u001b[0m, in \u001b[0;36mGANOversampling._train_gan\u001b[0;34m(self, generator, discriminator, gan_model, X_minority, latent_dim, epochs, batch_size)\u001b[0m\n\u001b[1;32m     98\u001b[0m real_data \u001b[38;5;241m=\u001b[39m X_minority\u001b[38;5;241m.\u001b[39miloc[idx]\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# Train discriminator\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m d_loss_real \u001b[38;5;241m=\u001b[39m \u001b[43mdiscriminator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreal_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m d_loss_fake \u001b[38;5;241m=\u001b[39m discriminator\u001b[38;5;241m.\u001b[39mtrain_on_batch(fake_data, np\u001b[38;5;241m.\u001b[39mzeros((batch_size, \u001b[38;5;241m1\u001b[39m)))\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# Train generator\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/CM3070/code/.final/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:598\u001b[0m, in \u001b[0;36mTensorFlowTrainer.train_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, return_dict)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdata\u001b[39m():\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m (x, y, sample_weight)\n\u001b[0;32m--> 598\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    599\u001b[0m logs \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mmap_structure(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39marray(x), logs)\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict:\n",
      "File \u001b[0;32m~/dev/CM3070/code/.final/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:224\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps_per_execution), iterator\n\u001b[1;32m    223\u001b[0m     ):\n\u001b[0;32m--> 224\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mone_step_on_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/dev/CM3070/code/.final/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/dev/CM3070/code/.final/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:110\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.one_step_on_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;129m@tf\u001b[39m\u001b[38;5;241m.\u001b[39mautograph\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mdo_not_convert\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mone_step_on_data\u001b[39m(data):\n\u001b[1;32m    109\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Runs a single training step on a batch of data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m reduce_per_replica(\n\u001b[1;32m    112\u001b[0m         outputs,\n\u001b[1;32m    113\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy,\n\u001b[1;32m    114\u001b[0m         reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    115\u001b[0m     )\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/dev/CM3070/code/.final/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:66\u001b[0m, in \u001b[0;36mTensorFlowTrainer.train_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     58\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(x)\n\u001b[1;32m     59\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_loss(\n\u001b[1;32m     60\u001b[0m     x\u001b[38;5;241m=\u001b[39mx,\n\u001b[1;32m     61\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     65\u001b[0m )\n\u001b[0;32m---> 66\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_loss_tracker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_state\u001b[49m(\n\u001b[1;32m     67\u001b[0m     loss, sample_weight\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mshape(tree\u001b[38;5;241m.\u001b[39mflatten(x)[\u001b[38;5;241m0\u001b[39m])[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     68\u001b[0m )\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mscale_loss(loss)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'update_state'"
     ]
    }
   ],
   "source": [
    "ganOversampling = GANOversampling(X_train, y_train)\n",
    "ganOversampling.apply_gan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7dc05b2b-e3c6-4553-af15-b6f60c0e5cdb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'OversamplingTechniques' object has no attribute '_build_gan'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m oversampling\u001b[38;5;241m.\u001b[39mapply_borderline_smote()\n\u001b[1;32m      8\u001b[0m oversampling\u001b[38;5;241m.\u001b[39mapply_random_oversampling()\n\u001b[0;32m----> 9\u001b[0m \u001b[43moversampling\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gan\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m oversampling\u001b[38;5;241m.\u001b[39mapply_wgan()\n",
      "Cell \u001b[0;32mIn[43], line 48\u001b[0m, in \u001b[0;36mOversamplingTechniques.apply_gan\u001b[0;34m(self, latent_dim, epochs, batch_size)\u001b[0m\n\u001b[1;32m     46\u001b[0m X_minority \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Filter minority class\u001b[39;00m\n\u001b[1;32m     47\u001b[0m n_minority_samples \u001b[38;5;241m=\u001b[39m X_minority\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 48\u001b[0m generator, discriminator, gan_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_gan\u001b[49m(latent_dim, X_minority\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Train GAN\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_gan(generator, discriminator, gan_model, X_minority, latent_dim, epochs, batch_size)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'OversamplingTechniques' object has no attribute '_build_gan'"
     ]
    }
   ],
   "source": [
    "# Initialize the OversamplingTechniques class with training data\n",
    "oversampling = OversamplingTechniques(X_train, y_train)\n",
    "\n",
    "# Apply different oversampling techniques\n",
    "oversampling.apply_smote()\n",
    "oversampling.apply_adasyn()\n",
    "oversampling.apply_borderline_smote()\n",
    "oversampling.apply_random_oversampling()\n",
    "oversampling.apply_gan()\n",
    "oversampling.apply_wgan()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "94c8fb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Class Distribution After SMOTE:\n",
      "Class\n",
      "0    199020\n",
      "1    199020\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Apply SMOTE to balance the training data\n",
    "smote_X, smote_y = oversampling.get_resampled_data('SMOTE')\n",
    "\n",
    "# Check class distribution after SMOTE\n",
    "print(\"Training Class Distribution After SMOTE:\")\n",
    "print(pd.Series(smote_y).value_counts())\n",
    "\n",
    "# Visualize the balanced class distribution\n",
    "pd.Series(smote_y).value_counts().plot(kind='bar', title='Class Distribution (After SMOTE)', xlabel='Class', ylabel='Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d7ec8e-3d77-43b1-8cc9-32d2897d6e65",
   "metadata": {},
   "source": [
    "#### Class for calculating the time taken to execute the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d1964c58-14e2-4570-bccf-c5d078109853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class Timer:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the timer with no start time\"\"\"\n",
    "        self.start_time = None\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"Start the timer\"\"\"\n",
    "        self.start_time = time.time()        \n",
    "\n",
    "    def elapsed(self):\n",
    "        \"\"\"Calculate the time elapsed since the timer was started\"\"\"\n",
    "        if self.start_time is None:\n",
    "            raise ValueError(\"Timer has not been started. Call `start()` before `elapsed()`\")\n",
    "        elapsed_time = time.time() - self.start_time\n",
    "        return elapsed_time\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"Stop the timer and reset the start_time\"\"\"\n",
    "        self.start_time = None\n",
    "\n",
    "# Create the Timer object\n",
    "timer = Timer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71dede9-7686-495b-a0fd-af307b29b079",
   "metadata": {},
   "source": [
    "#### Machine Learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15a3e51-b44e-4cf8-8577-81af8f1cd7f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66380f9f-b2c1-4b2a-85a8-6dae1effdd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the timer\n",
    "timer.start()\n",
    "\n",
    "# Train a Random Forest Classifier on the balanced dataset\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Calculate the elapsed time for the training\n",
    "elapsed_time = timer.elapsed()\n",
    "print(f\"Elapsed time: {elapsed_time:.2f} seconds\")\n",
    "timer.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3660f4d8-a3ba-48b1-9ce7-45bfbeaf96ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the timer\n",
    "timer.start()\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the elapsed time for the training\n",
    "elapsed_time = timer.elapsed()\n",
    "print(f\"Elapsed time: {elapsed_time:.2f} seconds\")\n",
    "timer.stop()\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report:\\n\", classification_report(y_pred, y_test))\n",
    "print(\"Accuracy:\", accuracy_score(y_pred, y_test))\n",
    "\n",
    "# Visualize confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.matshow(conf_matrix, cmap='Blues', alpha=0.7)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        plt.text(x=j, y=i, s=conf_matrix[i, j], va='center', ha='center')\n",
    "\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('True Label')\n",
    "plt.ylabel('Predicted Label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb07a56-0627-4e27-9222-280388e0b7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Autoencoder model\n",
    "def build_autoencoder(input_dim):\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(input_dim,)),\n",
    "        # Encoder\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(16, activation='relu'),\n",
    "        layers.Dense(8, activation='relu'),  # Bottleneck (compressed representation)\n",
    "        # Decoder\n",
    "        layers.Dense(16, activation='relu'),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(input_dim, activation='sigmoid')  # Output layer matches input\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d8e80f-426a-463b-9e87-e45a0da88c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "# The Class feature is not required in an unsupervised learning model\n",
    "X = df.drop(columns=['Class'], axis=1)  # Features\n",
    "y = df['Class']  # Labels\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "# Separate normal (non-fraudulent) transactions for training the Autoencoder\n",
    "X_normal = X_normalized[y == 0]\n",
    "\n",
    "# Split the normal transactions into training and validation sets\n",
    "X_train, X_val = train_test_split(X_normal, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Autoencoder\n",
    "input_dim = X_train.shape[1]\n",
    "autoencoder = build_autoencoder(input_dim)\n",
    "\n",
    "# Compile the Autoencoder\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Start the timer\n",
    "timer.start()\n",
    "\n",
    "# Train the Autoencoder\n",
    "history = autoencoder.fit(\n",
    "    X_train, X_train,  # Input is the same as the target\n",
    "    validation_data=(X_val, X_val),\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    verbose=1\n",
    ")   \n",
    "\n",
    "# Calculate the elapsed time for the training\n",
    "elapsed_time = timer.elapsed()\n",
    "print(f\"Elapsed time: {elapsed_time:.2f} seconds\")\n",
    "timer.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53095a07-b811-4fb7-982a-998ed99bb7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b1715d-711e-442a-b220-4f27db156995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Autoencoder to calculate reconstruction errors\n",
    "X_reconstructed = autoencoder.predict(X_normalized)\n",
    "reconstruction_errors = np.mean(np.square(X_normalized - X_reconstructed), axis=1)\n",
    "\n",
    "# Set a threshold for anomalies based on normal transactions' errors\n",
    "threshold = np.percentile(reconstruction_errors[y == 0], 99)  # 98th percentile\n",
    "\n",
    "# Classify anomalies (fraud) based on reconstruction error\n",
    "y_pred = (reconstruction_errors > threshold).astype(int)\n",
    "\n",
    "# Evaluate the results\n",
    "print(\"Classification Report:\\n\", classification_report(y, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y, y_pred))\n",
    "\n",
    "# Visualize reconstruction error distributions\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(reconstruction_errors[y == 0], bins=50, alpha=0.6, label='Normal')\n",
    "plt.hist(reconstruction_errors[y == 1], bins=50, alpha=0.6, label='Fraud')\n",
    "plt.axvline(threshold, color='red', linestyle='--', label='Threshold')\n",
    "plt.xlabel('Reconstruction Error')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.title('Reconstruction Error Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160592c4-86ba-4f67-b0dc-8fb9fb5a0e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize confusion matrix\n",
    "conf_matrix = confusion_matrix(y, y_pred)\n",
    "plt.matshow(conf_matrix, cmap='Blues', alpha=0.7)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        plt.text(x=j, y=i, s=conf_matrix[i, j], va='center', ha='center')\n",
    "\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('True Label')\n",
    "plt.ylabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3973921-3158-478f-9d60-903e58a67aef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031abaac-e34c-48e4-a0fa-fd63e937ab49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries (uncomment if needed)\n",
    "# !pip install cudf-cu11 cuml-cu11 --extra-index-url=https://pypi.nvidia.com\n",
    "# !pip install tensorflow keras\n",
    "\n",
    "import cudf\n",
    "import cuml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from cuml.preprocessing import MinMaxScaler\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# ============================================\n",
    "# Step 1: Load and preprocess the dataset\n",
    "# ============================================\n",
    "# Load the dataset using RAPIDS (GPU-accelerated Pandas alternative)\n",
    "data_path = \"creditcard.csv\"  # Replace with the path to the Kaggle dataset\n",
    "df = cudf.read_csv(data_path)\n",
    "\n",
    "# Filter only fraud transactions (Class == 1)\n",
    "fraud_data = df[df[\"Class\"] == 1].reset_index(drop=True)\n",
    "fraud_data = fraud_data.drop([\"Class\"], axis=1)  # Drop the class label as we focus on features\n",
    "\n",
    "# Scale features using RAPIDS MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "fraud_data_scaled = scaler.fit_transform(fraud_data)\n",
    "\n",
    "# Convert scaled fraud data back to NumPy for TensorFlow compatibility\n",
    "fraud_data_np = fraud_data_scaled.astype(np.float32)\n",
    "\n",
    "# ============================================\n",
    "# Step 2: Define the WGAN architecture\n",
    "# ============================================\n",
    "\n",
    "# Define constants\n",
    "LATENT_DIM = 100  # Size of the noise vector (input to the generator)\n",
    "FEATURE_DIM = fraud_data_np.shape[1]  # Number of features in the fraud data\n",
    "N_CRITIC = 5  # Number of discriminator updates per generator update\n",
    "CLIP_VALUE = 0.01  # Weight clipping value\n",
    "\n",
    "# Define the generator\n",
    "def build_generator():\n",
    "    input_noise = Input(shape=(LATENT_DIM,))\n",
    "    x = Dense(128)(input_noise)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = BatchNormalization(momentum=0.8)(x)\n",
    "    x = Dense(256)(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = BatchNormalization(momentum=0.8)(x)\n",
    "    x = Dense(FEATURE_DIM, activation=\"tanh\")(x)\n",
    "    return Model(input_noise, x, name=\"Generator\")\n",
    "\n",
    "# Define the discriminator (critic in WGAN terms)\n",
    "def build_critic():\n",
    "    input_data = Input(shape=(FEATURE_DIM,))\n",
    "    x = Dense(256)(input_data)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Dense(128)(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Dense(1)(x)  # Output is unbounded for Wasserstein loss\n",
    "    return Model(input_data, x, name=\"Critic\")\n",
    "\n",
    "# Initialize generator and critic\n",
    "generator = build_generator()\n",
    "critic = build_critic()\n",
    "\n",
    "# Define optimizers\n",
    "optimizer = RMSprop(learning_rate=0.00005)\n",
    "\n",
    "# Compile critic\n",
    "critic.compile(loss=\"mse\", optimizer=optimizer)\n",
    "\n",
    "# ============================================\n",
    "# Step 3: WGAN Training Loop\n",
    "# ============================================\n",
    "\n",
    "# Function to generate random noise\n",
    "def generate_noise(batch_size):\n",
    "    return np.random.normal(0, 1, (batch_size, LATENT_DIM))\n",
    "\n",
    "# Function to train WGAN\n",
    "def train_wgan(data, epochs=10000, batch_size=64):\n",
    "    half_batch = batch_size // 2\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        for _ in range(N_CRITIC):\n",
    "            # Sample real data and generate fake data\n",
    "            idx = np.random.randint(0, data.shape[0], half_batch)\n",
    "            real_samples = data[idx]\n",
    "            noise = generate_noise(half_batch)\n",
    "            fake_samples = generator.predict(noise)\n",
    "            \n",
    "            # Train critic\n",
    "            real_loss = critic.train_on_batch(real_samples, -np.ones((half_batch, 1)))\n",
    "            fake_loss = critic.train_on_batch(fake_samples, np.ones((half_batch, 1)))\n",
    "            critic_loss = 0.5 * np.add(real_loss, fake_loss)\n",
    "            \n",
    "            # Clip critic weights\n",
    "            for layer in critic.layers:\n",
    "                weights = layer.get_weights()\n",
    "                weights = [np.clip(w, -CLIP_VALUE, CLIP_VALUE) for w in weights]\n",
    "                layer.set_weights(weights)\n",
    "        \n",
    "        # Train generator\n",
    "        noise = generate_noise(batch_size)\n",
    "        generator_loss = critic.train_on_batch(generator.predict(noise), -np.ones((batch_size, 1)))\n",
    "        \n",
    "        # Print progress\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch} | Critic Loss: {critic_loss:.4f} | Generator Loss: {generator_loss:.4f}\")\n",
    "    \n",
    "    return generator\n",
    "\n",
    "# Train the WGAN\n",
    "generator_trained = train_wgan(fraud_data_np, epochs=5000, batch_size=128)\n",
    "\n",
    "# ============================================\n",
    "# Step 4: Generate synthetic fraud transactions\n",
    "# ============================================\n",
    "def generate_synthetic_data(generator, num_samples):\n",
    "    noise = generate_noise(num_samples)\n",
    "    synthetic_data = generator.predict(noise)\n",
    "    synthetic_data_rescaled = scaler.inverse_transform(synthetic_data)\n",
    "    return synthetic_data_rescaled\n",
    "\n",
    "# Generate 1000 synthetic fraud samples\n",
    "synthetic_fraud_data = generate_synthetic_data(generator_trained, num_samples=1000)\n",
    "\n",
    "# Convert synthetic data to Pandas DataFrame for further use\n",
    "synthetic_fraud_df = pd.DataFrame(synthetic_fraud_data, columns=fraud_data.columns)\n",
    "\n",
    "# Save to CSV\n",
    "synthetic_fraud_df.to_csv(\"synthetic_fraud_data.csv\", index=False)\n",
    "print(\"Synthetic fraud data saved as synthetic_fraud_data.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "@deathbeds/jupyterlab-fonts": {
   "styles": {
    ":root": {
     "--jp-content-font-size1": "14px"
    }
   }
  },
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

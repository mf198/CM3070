{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4b18613",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection System  \n",
    "  \n",
    "## Project Prototype\n",
    "  \n",
    "  \n",
    "Author: Marco Fontana"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6618ea38-80f4-4bf2-8b7d-bea0c7ef9756",
   "metadata": {},
   "source": [
    "## **Implementation** \n",
    "\n",
    "Before starting code development, I prepared an environment that would allow me to write and test the code and track all the changes I made.   \n",
    "The project is written in a Jupyter Notebook, in Python, and uses several third-party libraries specific to Machine Learning and Deep Learning algorithms. Therefore, before I could write code, I had to install all the necessary components on my PC's operating system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28038ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "!pip install numpy pandas tensorflow scikit-learn imbalanced-learn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "913404df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-25 11:14:28.090980: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-25 11:14:28.094435: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-25 11:14:28.104917: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1737800068.122685   16409 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1737800068.127585   16409 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-25 11:14:28.146439: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE, SVMSMOTE, RandomOverSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd501fdb-95f3-4795-94c7-bdc37a1648e6",
   "metadata": {},
   "source": [
    "### **Dataset analysis**\n",
    "\n",
    "The first phase of the project is dedicated to the analysis of the dataset. Before proceeding to the implementation of the code, it is necessary to have a deep understanding of the available data in order to understand whether modifications or cleaning operations are necessary to make the dataset suitable for the ML and DL algorithms that I am going to use, thus increasing its performance.\n",
    "Furthermore, since the dataset used contains financial data, it is necessary to verify that there is no sensitive information of the user or payment institution, which could lead to confidentiality or ethical problems.\n",
    "\n",
    "In the description of the dataset[] it is stated that for confidentiality reasons the content has been obscured via a PCA[] transformation; the feature name itself has been changed to a symbolic name (V1 to V28); the only features that have not been changed are Time and Amount.  \n",
    "The feature Time represents the number of seconds between each transaction and the first transaction, while Amount represents the amount of the transaction.  \n",
    "\n",
    "Transforming and obfuscating the data and features of the dataset ensures that it does not contain sensitive information and guarantees that there are no confidentiality issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "368b6d72-36f9-4c4f-9316-f8ae64a3cbe5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('creditcard.csv')\n",
    "\n",
    "# Show dataset info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359aa9f9-ea78-4af3-b8c2-bd8ebc20654d",
   "metadata": {},
   "source": [
    "The dataset consists of 284807 records and is described by 31 features.  \n",
    "The data are all of type float64, except for the feature 'Class' which is of type int64.\n",
    "\n",
    "#### **Checking for missing values**\n",
    "\n",
    "The following code checks for missing values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "413cef4d-480b-41ed-adaa-0da8876553e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of missing values: Time      0\n",
      "V1        0\n",
      "V2        0\n",
      "V3        0\n",
      "V4        0\n",
      "V5        0\n",
      "V6        0\n",
      "V7        0\n",
      "V8        0\n",
      "V9        0\n",
      "V10       0\n",
      "V11       0\n",
      "V12       0\n",
      "V13       0\n",
      "V14       0\n",
      "V15       0\n",
      "V16       0\n",
      "V17       0\n",
      "V18       0\n",
      "V19       0\n",
      "V20       0\n",
      "V21       0\n",
      "V22       0\n",
      "V23       0\n",
      "V24       0\n",
      "V25       0\n",
      "V26       0\n",
      "V27       0\n",
      "V28       0\n",
      "Amount    0\n",
      "Class     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNumber of missing values:\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a944d9fd-f5d8-4ae6-8442-ccad3bd3588b",
   "metadata": {},
   "source": [
    "The dataset contains no missing values, so no manual editing operation is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "437474b6-81f6-47bc-9af9-fc81cd5d602f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 5 records of the dataset\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d821da-77a7-46fa-921a-a40922cf9f1c",
   "metadata": {},
   "source": [
    "From the analysis of some records, it can be seen that the Time and Amount features have not been transformed.\n",
    "The Time feature is not useful in my research, since it does not provide a particular pattern related to the transaction; I could transform it into a date and time value, but since I have no information about the time of the first transaction I would have to create non-real data; that is why I decided to remove it from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdf6c22-24ff-4372-95da-40b23e61c12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da17c9f7-9bce-4470-9be1-723278911fe6",
   "metadata": {},
   "source": [
    "The 'Amount' feature is of type int64 and the values it contains can vary widely between transactons.  \n",
    "Some ML algorithms (SVM, gradient boosting, etc.) perform better when features are on a similar scale, and since the feature ‘Amount’ can have a significant variance, scaling helps stabilise the performance of the model.\n",
    "\n",
    "I did not delete the 'Amount' feature because the economic value of the transaction can be of great importance for identifying fraud patterns.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8d207f-e9a7-4992-a33b-bbc6c45cfca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply scaling to the 'Amount' feature\n",
    "df['Amount'] = StandardScaler().fit_transform(df[['Amount']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e03e248-3e7d-40b1-8002-8c5752d80fb8",
   "metadata": {},
   "source": [
    "The StandardScaler is a data preprocessing technique commonly used in machine learning to scale or normalize features so that they have a mean of 0 and a standard deviation of 1. This is particularly important for many machine learning algorithms that are sensitive to the scale of input features, such as SVMs (Support Vector Machines), k-NN (k-Nearest Neighbors), and Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8758f203-c92c-41b8-b3bf-be5f1a5ce0e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0.244964</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.342475</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>1.160686</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.140534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>-0.073403</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9       V10  ...       V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  0.090794  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  0.207643  ...  0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  0.753074  ... -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28    Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  0.244964      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724 -0.342475      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  1.160686      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  0.140534      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153 -0.073403      0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b72e82e4-e2b8-4e72-8510-b88db0a5d30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Class 1 records: 0.173%\n"
     ]
    }
   ],
   "source": [
    "# Convert the Class column to a NumPy array\n",
    "class_array = df['Class'].to_numpy()\n",
    "\n",
    "# Calculate the percentage of Class 1 records (frauds)\n",
    "percentage_class_1 = (np.sum(class_array == 1) / len(class_array)) * 100\n",
    "\n",
    "print(f\"Percentage of Class 1 records: {percentage_class_1:.3f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b01655e-7ef6-4897-a023-6ec2ef26d553",
   "metadata": {},
   "source": [
    "### Class for calculating the time taken to execute the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b485206-a4fb-462f-8358-9861e00ac924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "class Timer:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the timer with no start time\"\"\"\n",
    "        self.start_time = None\n",
    "\n",
    "    def start(self):\n",
    "        \"\"\"Start the timer\"\"\"\n",
    "        self.start_time = time.time()        \n",
    "\n",
    "    def elapsed(self):\n",
    "        \"\"\"Calculate the time elapsed since the timer was started\"\"\"\n",
    "        if self.start_time is None:\n",
    "            raise ValueError(\"Timer has not been started. Call `start()` before `elapsed()`\")\n",
    "        elapsed_time = time.time() - self.start_time\n",
    "        return elapsed_time\n",
    "\n",
    "    def stop(self):\n",
    "        \"\"\"Stop the timer and reset the start_time\"\"\"\n",
    "        self.start_time = None\n",
    "\n",
    "# Create the Timer object\n",
    "timer = Timer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1344994f-b1c9-41fb-b07e-ed2418c0ea55",
   "metadata": {},
   "source": [
    "### Balancing the dataset\n",
    "\n",
    "The dataset is very unbalanced, so I will use different technique to make the two classes equivalent in the number of records.  \n",
    "The balancing of the dataset is done after its division into training and test data, so that the latter contain no ‘synthetic’ data.  \n",
    "\n",
    "Below I created a class for applying oversampling methods on the dataset. I used several oversampling methods to check which one was best in generating synthetic data. The methods implemented are: SMOTE, ADASYN, Borderline-SMOTE, SVMSMOTE and Random Oversampling.  \n",
    "In the following tests, these different techniques will be compared with ML and DL algorithms.  \n",
    "\n",
    "In the following tests, these different techniques will be compared with ML and DL algorithms. I selected these techniques as a result of reading research in which they were used. In analyzing the results I will have to take into account the number of false positives, which also have an economic impact for the bank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131c2b68-49ab-4636-b37a-a95dd5bc4d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OversamplingTechniques:\n",
    "    def __init__(self, X, y):\n",
    "        \"\"\"\n",
    "        Initialize the class with the original dataset features (X) and target (y).\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.results = {}\n",
    "\n",
    "    def apply_smote(self):\n",
    "        \"\"\"\n",
    "        Apply SMOTE to the dataset and save the oversampled dataset.\n",
    "        \"\"\"\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_resampled, y_resampled = smote.fit_resample(self.X, self.y)\n",
    "        self.results['SMOTE'] = (X_resampled, y_resampled)\n",
    "\n",
    "    def apply_adasyn(self):\n",
    "        \"\"\"\n",
    "        Apply ADASYN to the dataset and save the oversampled dataset.\n",
    "        \"\"\"\n",
    "        adasyn = ADASYN(random_state=42)\n",
    "        X_resampled, y_resampled = adasyn.fit_resample(self.X, self.y)\n",
    "        self.results['ADASYN'] = (X_resampled, y_resampled)\n",
    "\n",
    "    def apply_borderline_smote(self):\n",
    "        \"\"\"\n",
    "        Apply Borderline-SMOTE to the dataset and save the oversampled dataset.\n",
    "        \"\"\"\n",
    "        borderline_smote = BorderlineSMOTE(random_state=42)\n",
    "        X_resampled, y_resampled = borderline_smote.fit_resample(self.X, self.y)\n",
    "        self.results['Borderline-SMOTE'] = (X_resampled, y_resampled)\n",
    "\n",
    "    def apply_svmsmote(self):\n",
    "        \"\"\"\n",
    "        Apply SVMSMOTE to the dataset and save the oversampled dataset.\n",
    "        \"\"\"\n",
    "        svmsmote = SVMSMOTE(random_state=42)\n",
    "        X_resampled, y_resampled = svmsmote.fit_resample(self.X, self.y)\n",
    "        self.results['SVMSMOTE'] = (X_resampled, y_resampled)\n",
    "\n",
    "    def apply_random_oversampling(self):\n",
    "        \"\"\"\n",
    "        Apply Random Oversampling to the dataset and save the oversampled dataset.\n",
    "        \"\"\"\n",
    "        random_oversampler = RandomOverSampler(random_state=42)\n",
    "        X_resampled, y_resampled = random_oversampler.fit_resample(self.X, self.y)\n",
    "        self.results['Random Oversampling'] = (X_resampled, y_resampled)\n",
    "\n",
    "    def get_resampled_data(self, method):\n",
    "        \"\"\"\n",
    "        Retrieve the resampled dataset for a given oversampling method.\n",
    "        :param method: String indicating the oversampling method (e.g., 'SMOTE').\n",
    "        :return: Tuple of resampled features (X) and target (y).\n",
    "        \"\"\"\n",
    "        return self.results.get(method, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b0fc07-d373-4c9f-9669-a359678bf872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "X = df.drop(columns=['Class'])  # Features\n",
    "y = df['Class']                 # Labels\n",
    "\n",
    "# Split the data into train and test sets (to avoid data leakage)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5a628f-9846-4be8-8899-defb81c47a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display class distribution before any oversampling technique is applied\n",
    "print(\"Class Distribution Before oversampling:\")\n",
    "print(df['Class'].value_counts())\n",
    "df['Class'].value_counts().plot(kind='bar', title='Class Distribution (Before oversampling)', xlabel='Class', ylabel='Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc05b2b-e3c6-4553-af15-b6f60c0e5cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OversamplingTechniques class with training data\n",
    "oversampling = OversamplingTechniques(X_train, y_train)\n",
    "\n",
    "# Apply different oversampling techniques\n",
    "oversampling.apply_smote()\n",
    "oversampling.apply_adasyn()\n",
    "oversampling.apply_borderline_smote()\n",
    "oversampling.apply_svmsmote()\n",
    "oversampling.apply_random_oversampling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c8fb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to balance the training data\n",
    "smote_X, smote_y = oversampling.get_resampled_data('SMOTE')\n",
    "\n",
    "# Check class distribution after SMOTE\n",
    "print(\"Training Class Distribution After SMOTE:\")\n",
    "print(pd.Series(smote_y).value_counts())\n",
    "\n",
    "# Visualize the balanced class distribution\n",
    "pd.Series(smote_y).value_counts().plot(kind='bar', title='Class Distribution (After SMOTE)', xlabel='Class', ylabel='Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207a3d73-ce3e-45c7-a047-3e5a56da374e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66380f9f-b2c1-4b2a-85a8-6dae1effdd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the timer\n",
    "timer.start()\n",
    "\n",
    "# Train a Random Forest Classifier on the balanced dataset\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Calculate the elapsed time for the training\n",
    "elapsed_time = timer.elapsed()\n",
    "print(f\"Elapsed time: {elapsed_time:.2f} seconds\")\n",
    "timer.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3660f4d8-a3ba-48b1-9ce7-45bfbeaf96ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the timer\n",
    "timer.start()\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the elapsed time for the training\n",
    "elapsed_time = timer.elapsed()\n",
    "print(f\"Elapsed time: {elapsed_time:.2f} seconds\")\n",
    "timer.stop()\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report:\\n\", classification_report(y_pred, y_test))\n",
    "print(\"Accuracy:\", accuracy_score(y_pred, y_test))\n",
    "\n",
    "# Visualize confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.matshow(conf_matrix, cmap='Blues', alpha=0.7)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        plt.text(x=j, y=i, s=conf_matrix[i, j], va='center', ha='center')\n",
    "\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('True Label')\n",
    "plt.ylabel('Predicted Label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb07a56-0627-4e27-9222-280388e0b7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Autoencoder model\n",
    "def build_autoencoder(input_dim):\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(input_dim,)),\n",
    "        # Encoder\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(16, activation='relu'),\n",
    "        layers.Dense(8, activation='relu'),  # Bottleneck (compressed representation)\n",
    "        # Decoder\n",
    "        layers.Dense(16, activation='relu'),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(input_dim, activation='sigmoid')  # Output layer matches input\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d8e80f-426a-463b-9e87-e45a0da88c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "# The Class feature is not required in an unsupervised learning model\n",
    "X = df.drop(columns=['Class'], axis=1)  # Features\n",
    "y = df['Class']  # Labels\n",
    "\n",
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "# Separate normal (non-fraudulent) transactions for training the Autoencoder\n",
    "X_normal = X_normalized[y == 0]\n",
    "\n",
    "# Split the normal transactions into training and validation sets\n",
    "X_train, X_val = train_test_split(X_normal, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Autoencoder\n",
    "input_dim = X_train.shape[1]\n",
    "autoencoder = build_autoencoder(input_dim)\n",
    "\n",
    "# Compile the Autoencoder\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Start the timer\n",
    "timer.start()\n",
    "\n",
    "# Train the Autoencoder\n",
    "history = autoencoder.fit(\n",
    "    X_train, X_train,  # Input is the same as the target\n",
    "    validation_data=(X_val, X_val),\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    verbose=1\n",
    ")   \n",
    "\n",
    "# Calculate the elapsed time for the training\n",
    "elapsed_time = timer.elapsed()\n",
    "print(f\"Elapsed time: {elapsed_time:.2f} seconds\")\n",
    "timer.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53095a07-b811-4fb7-982a-998ed99bb7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b1715d-711e-442a-b220-4f27db156995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Autoencoder to calculate reconstruction errors\n",
    "X_reconstructed = autoencoder.predict(X_normalized)\n",
    "reconstruction_errors = np.mean(np.square(X_normalized - X_reconstructed), axis=1)\n",
    "\n",
    "# Set a threshold for anomalies based on normal transactions' errors\n",
    "threshold = np.percentile(reconstruction_errors[y == 0], 99)  # 98th percentile\n",
    "\n",
    "# Classify anomalies (fraud) based on reconstruction error\n",
    "y_pred = (reconstruction_errors > threshold).astype(int)\n",
    "\n",
    "# Evaluate the results\n",
    "print(\"Classification Report:\\n\", classification_report(y, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y, y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y, y_pred))\n",
    "\n",
    "# Visualize reconstruction error distributions\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(reconstruction_errors[y == 0], bins=50, alpha=0.6, label='Normal')\n",
    "plt.hist(reconstruction_errors[y == 1], bins=50, alpha=0.6, label='Fraud')\n",
    "plt.axvline(threshold, color='red', linestyle='--', label='Threshold')\n",
    "plt.xlabel('Reconstruction Error')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.title('Reconstruction Error Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160592c4-86ba-4f67-b0dc-8fb9fb5a0e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize confusion matrix\n",
    "conf_matrix = confusion_matrix(y, y_pred)\n",
    "plt.matshow(conf_matrix, cmap='Blues', alpha=0.7)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        plt.text(x=j, y=i, s=conf_matrix[i, j], va='center', ha='center')\n",
    "\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('True Label')\n",
    "plt.ylabel('Predicted Label')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kCM3070",
   "language": "python",
   "name": "kcm3070"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
